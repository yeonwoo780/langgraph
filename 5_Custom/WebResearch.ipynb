{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f6305fd",
   "metadata": {},
   "source": [
    "![image](../image/WebResearch1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2c6b076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../../\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a9a7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd66741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-2024-08-06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d70129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from pydantic import BaseModel, Field, field_validator\n",
    "\n",
    "direct_gen_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a Wikipedia writer. Write an outline for a Wikipedia page about a user-provided topic. Be comprehensive and specific.\",\n",
    "        ),\n",
    "        (\"user\", \"{topic}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class Subsection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    description: str = Field(..., title=\"Content of the subsection\")\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.description}\".strip()\n",
    "\n",
    "\n",
    "class Section(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    description: str = Field(..., title=\"Content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            f\"### {subsection.subsection_title}\\n\\n{subsection.description}\"\n",
    "            for subsection in self.subsections or []\n",
    "        )\n",
    "        return f\"## {self.section_title}\\n\\n{self.description}\\n\\n{subsections}\".strip()\n",
    "\n",
    "\n",
    "class Outline(BaseModel):\n",
    "    page_title: str = Field(..., title=\"Title of the Wikipedia page\")\n",
    "    sections: List[Section] = Field(\n",
    "        default_factory=list,\n",
    "        title=\"Titles and descriptions for each section of the Wikipedia page.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        sections = \"\\n\\n\".join(section.as_str for section in self.sections)\n",
    "        return f\"# {self.page_title}\\n\\n{sections}\".strip()\n",
    "\n",
    "\n",
    "generate_outline_direct = direct_gen_outline_prompt | llm.with_structured_output(\n",
    "    Outline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6edc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact of million-plus token context window language models on Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "## Introduction\n",
      "\n",
      "This section provides an overview of what the article will cover, including basic definitions and the significance of the topic.\n",
      "\n",
      "### Overview of Language Models\n",
      "\n",
      "A brief discussion on the evolution of language models, including their role in natural language processing.\n",
      "\n",
      "### Definition of Context Windows\n",
      "\n",
      "Explanation of what context windows are in the context of language models and why their size is important.\n",
      "\n",
      "### Introduction to Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "Explanation of RAG, its relevance in enhancing language model outputs, and its application in various domains.\n",
      "\n",
      "## Advancements in Context Window Sizes\n",
      "\n",
      "This section delves into the technological and research advancements that have led to the development of language models with million-plus token context windows.\n",
      "\n",
      "### Technological Developments\n",
      "\n",
      "Details about the technological improvements that have allowed the expansion of context windows in language models.\n",
      "\n",
      "### Research Innovations\n",
      "\n",
      "Research breakthroughs that have contributed to enabling extensive context windows.\n",
      "\n",
      "## Impact on RAG Systems\n",
      "\n",
      "Discussion on how million-plus token context windows are transforming RAG systems.\n",
      "\n",
      "### Improved Information Retrieval\n",
      "\n",
      "How larger context windows enhance the retrieval component of RAG by allowing more comprehensive input processing.\n",
      "\n",
      "### Enhanced Generation Capabilities\n",
      "\n",
      "Improvements in the generative component, thanks to access to larger and more relevant context.\n",
      "\n",
      "### Performance Metrics\n",
      "\n",
      "Analysis of benchmark studies comparing traditional and large context window RAG models.\n",
      "\n",
      "## Applications and Use Cases\n",
      "\n",
      "Exploration of practical applications and sectors where large context window RAG models are being implemented.\n",
      "\n",
      "### Industry Applications\n",
      "\n",
      "Examination of specific industries such as healthcare, legal, and finance that benefit from enhanced RAG models.\n",
      "\n",
      "### Academic and Research Applications\n",
      "\n",
      "Usage of these advanced models in research for comprehensive reviews and information synthesis.\n",
      "\n",
      "## Challenges and Limitations\n",
      "\n",
      "An overview of the current challenges and limitations facing million-plus token context models in RAG systems.\n",
      "\n",
      "### Technical Limitations\n",
      "\n",
      "Discussion on computational challenges, data handling, and latency issues.\n",
      "\n",
      "### Ethical Considerations\n",
      "\n",
      "Potential ethical implications, including privacy concerns and bias in more complex datasets.\n",
      "\n",
      "## Future Prospects\n",
      "\n",
      "Speculation on future developments in large context window models and their potential impacts on RAG.\n",
      "\n",
      "### Research Directions\n",
      "\n",
      "Potential future research directions and areas in need of exploration.\n",
      "\n",
      "### Technological Innovations\n",
      "\n",
      "Predictions about upcoming technological advancements that could further transform RAG systems.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "A summary of the article, highlighting the significance of the impact of million-plus token context windows on RAG, and reiterating the key takeaways from the discussion.\n"
     ]
    }
   ],
   "source": [
    "example_topic = \"Impact of million-plus token context window language models on RAG\"\n",
    "\n",
    "initial_outline = generate_outline_direct.invoke({\"topic\": example_topic})\n",
    "\n",
    "print(initial_outline.as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15579932",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_related_topics_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"I'm writing a Wikipedia page for a topic mentioned below. Please identify and recommend some Wikipedia pages on closely related subjects. I'm looking for examples that provide insights into interesting aspects commonly associated with this topic, or examples that help me understand the typical content and structure included in Wikipedia pages for similar topics.\n",
    "\n",
    "Please list the as many subjects and urls as you can.\n",
    "\n",
    "Topic of interest: {topic}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "class RelatedSubjects(BaseModel):\n",
    "    topics: List[str] = Field(\n",
    "        description=\"Comprehensive list of related subjects as background research.\",\n",
    "    )\n",
    "\n",
    "\n",
    "expand_chain = gen_related_topics_prompt | llm.with_structured_output(\n",
    "    RelatedSubjects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8568dc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RelatedSubjects(topics=['Natural Language Processing (NLP) https://en.wikipedia.org/wiki/Natural_language_processing', 'Large Language Models (LLMs) https://en.wikipedia.org/wiki/Large_language_model', 'Deep Learning https://en.wikipedia.org/wiki/Deep_learning', 'Recurrent Neural Networks https://en.wikipedia.org/wiki/Recurrent_neural_network', 'Transformer Models https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)', 'GPT-3 (Generative Pre-trained Transformer 3) https://en.wikipedia.org/wiki/GPT-3', 'Attention Mechanism in Neural Networks https://en.wikipedia.org/wiki/Attention_(machine_learning)', 'Tokenization in NLP https://en.wikipedia.org/wiki/Tokenization_(lexical_analysis)', 'Context Window in NLP https://en.wikipedia.org/wiki/Window_(computing)#In_natural_language_processing', 'Machine Reading Comprehension https://en.wikipedia.org/wiki/Machine_reading_comprehension', 'Retrieval-Augmented Generation (RAG) https://en.wikipedia.org/wiki/Retrieval-augmented_generation', 'Sequence Modeling https://en.wikipedia.org/wiki/Sequence_modeling', 'Artificial Intelligence https://en.wikipedia.org/wiki/Artificial_intelligence', 'Information Retrieval https://en.wikipedia.org/wiki/Information_retrieval', 'Semantic Memory in AI https://en.wikipedia.org/wiki/Semantic_memory#In_artificial_intelligence', 'Graph Neural Networks https://en.wikipedia.org/wiki/Graph_neural_network', 'Zero-shot Learning https://en.wikipedia.org/wiki/Zero-shot_learning', 'Transfer Learning https://en.wikipedia.org/wiki/Transfer_learning', 'Knowledge Graphs https://en.wikipedia.org/wiki/Knowledge_graph', 'Neural Network Learning Paradigm https://en.wikipedia.org/wiki/Artificial_neural_network_learning'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_subjects = await expand_chain.ainvoke({\"topic\": example_topic})\n",
    "related_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704e7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Editor(BaseModel):\n",
    "    affiliation: str = Field(\n",
    "        description=\"Primary affiliation of the editor.\",\n",
    "    )\n",
    "    name: str = Field(\n",
    "        description=\"Name of the editor.\", pattern=r\"^[a-zA-Z0-9_-]{1,64}$\"\n",
    "    )\n",
    "    role: str = Field(\n",
    "        description=\"Role of the editor in the context of the topic.\",\n",
    "    )\n",
    "    description: str = Field(\n",
    "        description=\"Description of the editor's focus, concerns, and motives.\",\n",
    "    )\n",
    "\n",
    "    @field_validator(\"name\", mode=\"before\")\n",
    "    def sanitize_name(cls, value: str) -> str:\n",
    "        return value.replace(\" \", \"\").replace(\".\", \"\")\n",
    "\n",
    "    @property\n",
    "    def persona(self) -> str:\n",
    "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
    "\n",
    "\n",
    "class Perspectives(BaseModel):\n",
    "    editors: List[Editor] = Field(\n",
    "        description=\"Comprehensive list of editors with their roles and affiliations.\",\n",
    "        # Add a pydantic validation/restriction to be at most M editors\n",
    "    )\n",
    "\n",
    "\n",
    "gen_perspectives_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You need to select a diverse (and distinct) group of Wikipedia editors who will work together to create a comprehensive article on the topic. Each of them represents a different perspective, role, or affiliation related to this topic.\\\n",
    "    You can use other Wikipedia pages of related topics for inspiration. For each editor, add a description of what they will focus on.\n",
    "\n",
    "    Wiki page outlines of related topics for inspiration:\n",
    "    {examples}\"\"\",\n",
    "        ),\n",
    "        (\"user\", \"Topic of interest: {topic}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_perspectives_chain = gen_perspectives_prompt | llm.with_structured_output(\n",
    "    Perspectives, method=\"function_calling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c34dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.runnables import chain as as_runnable\n",
    "\n",
    "wikipedia_retriever = WikipediaRetriever(load_all_available_meta=True, top_k_results=1)\n",
    "\n",
    "\n",
    "def format_doc(doc, max_length=1000):\n",
    "    related = \"- \".join(doc.metadata[\"categories\"])\n",
    "    return f\"### {doc.metadata['title']}\\n\\nSummary: {doc.page_content}\\n\\nRelated\\n{related}\"[\n",
    "        :max_length\n",
    "    ]\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(format_doc(doc) for doc in docs)\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def survey_subjects(topic: str):\n",
    "    related_subjects = await expand_chain.ainvoke({\"topic\": topic})\n",
    "    retrieved_docs = await wikipedia_retriever.abatch(\n",
    "        related_subjects.topics, return_exceptions=True\n",
    "    )\n",
    "    all_docs = []\n",
    "    for docs in retrieved_docs:\n",
    "        if isinstance(docs, BaseException):\n",
    "            continue\n",
    "        all_docs.extend(docs)\n",
    "    formatted = format_docs(all_docs)\n",
    "    return await gen_perspectives_chain.ainvoke({\"examples\": formatted, \"topic\": topic})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c981fabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/langgraph/lib/python3.11/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/ubuntu/miniforge3/envs/langgraph/lib/python3.11/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "perspectives = await survey_subjects.ainvoke(example_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55aa62f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'editors': [{'affiliation': 'Academic (Natural Language Processing)',\n",
       "   'name': 'Prof_Ling101',\n",
       "   'role': 'Researcher',\n",
       "   'description': 'Focuses on how large token context windows in language models can enhance Retrieval-Augmented Generation (RAG) by improving retrieval relevance and context understanding. They aim to analyze the efficiency improvements and cognitive load reduction in comprehension tasks through larger context windows.'},\n",
       "  {'affiliation': 'Industry (AI Technology Company)',\n",
       "   'name': 'AI_Tech_Lead',\n",
       "   'role': 'Engineer',\n",
       "   'description': 'Examines the implementation challenges and opportunities of deploying language models with million-plus token context windows in real-world RAG systems. Their focus is on scalability, computational costs, and integration with existing information retrieval systems.'},\n",
       "  {'affiliation': 'Tech Policy & Ethics Organization',\n",
       "   'name': 'Ethics_Advocate',\n",
       "   'role': 'Ethicist',\n",
       "   'description': 'Analyzes the ethical implications of using large context window language models in RAG systems, including privacy concerns, data usage policies, and the potential for bias. Their goal is to ensure responsible deployment and avoid reinforcing socio-technical inequalities.'},\n",
       "  {'affiliation': 'OpenAI',\n",
       "   'name': 'AI_Researcher',\n",
       "   'role': 'Research Scientist',\n",
       "   'description': \"Explores the technical advancements in large language models that enable million-plus token context windows. They seek to contribute to knowledge on improving RAG systems' performance, focusing on transformer architectures and attention mechanisms.\"},\n",
       "  {'affiliation': 'Journalism (Tech News)',\n",
       "   'name': 'Tech_Journalist',\n",
       "   'role': 'Reporter',\n",
       "   'description': 'Aims to communicate to the public how RAG systems enhanced by extensive token context windows could transform industries such as customer service, content creation, and research. They strive to provide insights on new capabilities and limitations of these AI systems.'},\n",
       "  {'affiliation': 'Government Research Institute',\n",
       "   'name': 'Gov_AI_Analyst',\n",
       "   'role': 'Policy Analyst',\n",
       "   'description': 'Evaluates the societal and economic impacts of advanced language models on public and private sectors. Their focus is to guide policy development that encourages innovation while addressing potential disruptions caused by AI advancements.'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perspectives.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7586f5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "\n",
    "def add_messages(left, right):\n",
    "    if not isinstance(left, list):\n",
    "        left = [left]\n",
    "    if not isinstance(right, list):\n",
    "        right = [right]\n",
    "    return left + right\n",
    "\n",
    "\n",
    "def update_references(references, new_references):\n",
    "    if not references:\n",
    "        references = {}\n",
    "    references.update(new_references)\n",
    "    return references\n",
    "\n",
    "\n",
    "def update_editor(editor, new_editor):\n",
    "    # Can only set at the outset\n",
    "    if not editor:\n",
    "        return new_editor\n",
    "    return editor\n",
    "\n",
    "\n",
    "class InterviewState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    references: Annotated[Optional[dict], update_references]\n",
    "    editor: Annotated[Optional[Editor], update_editor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b4bd003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "gen_qn_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an experienced Wikipedia writer and want to edit a specific page. \\\n",
    "Besides your identity as a Wikipedia writer, you have a specific focus when researching the topic. \\\n",
    "Now, you are chatting with an expert to get information. Ask good questions to get more useful information.\n",
    "\n",
    "When you have no more questions to ask, say \"Thank you so much for your help!\" to end the conversation.\\\n",
    "Please only ask one question at a time and don't ask what you have asked before.\\\n",
    "Your questions should be related to the topic you want to write.\n",
    "Be comprehensive and curious, gaining as much unique insight from the expert as possible.\\\n",
    "\n",
    "Stay true to your specific perspective:\n",
    "\n",
    "{persona}\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def tag_with_name(ai_message: AIMessage, name: str):\n",
    "    ai_message.name = name\n",
    "    return ai_message\n",
    "\n",
    "\n",
    "def swap_roles(state: InterviewState, name: str):\n",
    "    converted = []\n",
    "    for message in state[\"messages\"]:\n",
    "        if isinstance(message, AIMessage) and message.name != name:\n",
    "            message = HumanMessage(**message.model_dump(exclude={\"type\"}))\n",
    "        converted.append(message)\n",
    "    return {\"messages\": converted}\n",
    "\n",
    "\n",
    "@as_runnable\n",
    "async def generate_question(state: InterviewState):\n",
    "    editor = state[\"editor\"]\n",
    "    gn_chain = (\n",
    "        RunnableLambda(swap_roles).bind(name=editor.name)\n",
    "        | gen_qn_prompt.partial(persona=editor.persona)\n",
    "        | llm\n",
    "        | RunnableLambda(tag_with_name).bind(name=editor.name)\n",
    "    )\n",
    "    result = await gn_chain.ainvoke(state)\n",
    "    return {\"messages\": [result]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c9512c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Yes, I'm interested in how large token context windows can enhance Retrieval-Augmented Generation (RAG) by improving retrieval relevance and context understanding. Could you share insights on how large context windows in natural language processing might affect the efficiency of retrieval processes in RAG systems?\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(f\"So you said you were writing an article on {example_topic}?\")\n",
    "]\n",
    "question = await generate_question.ainvoke(\n",
    "    {\n",
    "        \"editor\": perspectives.editors[0],\n",
    "        \"messages\": messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "question[\"messages\"][0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f97ecdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queries(BaseModel):\n",
    "    queries: List[str] = Field(\n",
    "        description=\"Comprehensive list of search engine queries to answer the user's questions.\",\n",
    "    )\n",
    "\n",
    "\n",
    "gen_queries_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful research assistant. Query the search engine to answer the user's questions.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "gen_queries_chain = gen_queries_prompt | llm.with_structured_output(\n",
    "    Queries, include_raw=True, method=\"function_calling\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3dde597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['impact of large token context windows on RAG systems',\n",
       " 'how large context windows enhance retrieval relevance',\n",
       " 'role of context length in improving context understanding RAG',\n",
       " 'large context windows efficiency in natural language processing']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = await gen_queries_chain.ainvoke(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "queries[\"parsed\"].queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ade640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerWithCitations(BaseModel):\n",
    "    answer: str = Field(\n",
    "        description=\"Comprehensive answer to the user's question with citations.\",\n",
    "    )\n",
    "    cited_urls: List[str] = Field(\n",
    "        description=\"List of urls cited in the answer.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"{self.answer}\\n\\nCitations:\\n\\n\" + \"\\n\".join(\n",
    "            f\"[{i+1}]: {url}\" for i, url in enumerate(self.cited_urls)\n",
    "        )\n",
    "\n",
    "\n",
    "gen_answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are an expert who can use information effectively. You are chatting with a Wikipedia writer who wants\\\n",
    " to write a Wikipedia page on the topic you know. You have gathered the related information and will now use the information to form a response.\n",
    "\n",
    "Make your response as informative as possible and make sure every sentence is supported by the gathered information.\n",
    "Each response must be backed up by a citation from a reliable source, formatted as a footnote, reproducing the URLS after your response.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\", optional=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "gen_answer_chain = gen_answer_prompt | llm.with_structured_output(\n",
    "    AnswerWithCitations, include_raw=True\n",
    ").with_config(run_name=\"GenerateAnswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10477123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "search_engine = TavilySearchResults(max_results=4)\n",
    "\n",
    "\n",
    "@tool\n",
    "async def search_engine(query: str):\n",
    "    \"\"\"Search engine to the internet.\"\"\"\n",
    "    results = tavily_search.invoke(query)\n",
    "    return [{\"content\": r[\"content\"], \"url\": r[\"url\"]} for r in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74d55e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "async def gen_answer(\n",
    "    state: InterviewState,\n",
    "    config: Optional[RunnableConfig] = None,\n",
    "    name: str = \"Subject_Matter_Expert\",\n",
    "    max_str_len: int = 15000,\n",
    "):\n",
    "    swapped_state = swap_roles(state, name)  # Convert all other AI messages\n",
    "    queries = await gen_queries_chain.ainvoke(swapped_state)\n",
    "    query_results = await search_engine.abatch(\n",
    "        queries[\"parsed\"].queries, config, return_exceptions=True\n",
    "    )\n",
    "    successful_results = [\n",
    "        res for res in query_results if not isinstance(res, Exception)\n",
    "    ]\n",
    "    all_query_results = {\n",
    "        res[\"url\"]: res[\"content\"] for results in successful_results for res in results\n",
    "    }\n",
    "    # We could be more precise about handling max token length if we wanted to here\n",
    "    dumped = json.dumps(all_query_results)[:max_str_len]\n",
    "    ai_message: AIMessage = queries[\"raw\"]\n",
    "    tool_call = queries[\"raw\"].tool_calls[0]\n",
    "    tool_id = tool_call[\"id\"]\n",
    "    tool_message = ToolMessage(tool_call_id=tool_id, content=dumped)\n",
    "    swapped_state[\"messages\"].extend([ai_message, tool_message])\n",
    "    # Only update the shared state with the final answer to avoid\n",
    "    # polluting the dialogue history with intermediate messages\n",
    "    generated = await gen_answer_chain.ainvoke(swapped_state)\n",
    "    cited_urls = set(generated[\"parsed\"].cited_urls)\n",
    "    # Save the retrieved information to a the shared state for future reference\n",
    "    cited_references = {k: v for k, v in all_query_results.items() if k in cited_urls}\n",
    "    formatted_message = AIMessage(name=name, content=generated[\"parsed\"].as_str)\n",
    "    return {\"messages\": [formatted_message], \"references\": cited_references}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65e98a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Large token context windows can significantly enhance Retrieval-Augmented Generation (RAG) systems by improving both retrieval relevance and context understanding. In natural language processing (NLP), a context window refers to the portion of surrounding text that a model considers while making predictions or generating text. Increasing the size of this window means that the model has more information to work with, which directly impacts its ability to understand and generate coherent and relevant outputs.\\n\\nFirstly, larger context windows allow RAG systems to gather more comprehensive information from a single retrieval pass. Instead of being limited to a few sentences or paragraphs, systems can take into account entire documents or multiple segments of text. This capability expands the amount of retrievable data, offering greater chances to find relevant information, thereby improving the relevance of retrieved passages to the user's query[^1^].\\n\\nMoreover, the enhanced understanding afforded by large context windows allows for better disambiguation of terms and understanding of nuanced context. For instance, many queries can have multiple meanings depending on context, and a larger window enables the model to assess these nuances and retrieve the most relevant information accordingly. This also reduces the likelihood of retrieving irrelevant or redundant information, thus making the retrieval process more efficient[^2^].\\n\\nIn application to RAG, where retrieval plays a crucial role in augmenting generative tasks with external knowledge, having a larger context window can significantly improve the generative quality by providing more relevant background information that informs and enriches the generation process[^3^]. Large context windows also enable capturing longer dependencies across the text, which is critical in creating responses that are contextually aware and coherent over extended interactions or document sections.\\n\\nCitations:\\n\\n[1]: https://arxiv.org/abs/2105.04387\\n[2]: https://arxiv.org/abs/2005.11401\\n[3]: https://arxiv.org/abs/1906.06762\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_answer = await gen_answer(\n",
    "    {\"messages\": [HumanMessage(content=question[\"messages\"][0].content)]}\n",
    ")\n",
    "example_answer[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aed59e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_num_turns = 5\n",
    "from langgraph.pregel import RetryPolicy\n",
    "\n",
    "\n",
    "def route_messages(state: InterviewState, name: str = \"Subject_Matter_Expert\"):\n",
    "    messages = state[\"messages\"]\n",
    "    num_responses = len(\n",
    "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
    "    )\n",
    "    if num_responses >= max_num_turns:\n",
    "        return END\n",
    "    last_question = messages[-2]\n",
    "    if last_question.content.endswith(\"Thank you so much for your help!\"):\n",
    "        return END\n",
    "    return \"ask_question\"\n",
    "\n",
    "\n",
    "builder = StateGraph(InterviewState)\n",
    "\n",
    "builder.add_node(\"ask_question\", generate_question, retry=RetryPolicy(max_attempts=5))\n",
    "builder.add_node(\"answer_question\", gen_answer, retry=RetryPolicy(max_attempts=5))\n",
    "builder.add_conditional_edges(\"answer_question\", route_messages)\n",
    "builder.add_edge(\"ask_question\", \"answer_question\")\n",
    "\n",
    "builder.add_edge(START, \"ask_question\")\n",
    "interview_graph = builder.compile(checkpointer=False).with_config(\n",
    "    run_name=\"Conduct Interviews\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d531ac86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(interview_graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e3e83ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ask_question\n",
      "--  [AIMessage(content=\"Yes, that's correct. Could you explain how larger token context windows can specifically enhance the relevance of retrieved documents in a RAG framework?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 239, 'tota\n",
      "answer_question\n",
      "--  [AIMessage(content=\"Larger token context windows in Retrieval-Augmented Generation (RAG) frameworks significantly enhance the relevance of retrieved documents by providing a more comprehensive context for understanding queries and documents. Traditional language models have been limited by smaller c\n",
      "ask_question\n",
      "--  [AIMessage(content='Thank you for explaining that. How do larger context windows contribute to the reduction of cognitive load in comprehension tasks within the RAG framework?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 557, 'to\n",
      "answer_question\n",
      "--  [AIMessage(content='Larger context windows in language models contribute significantly to the reduction of cognitive load in comprehension tasks within the RAG framework. Cognitive load refers to the amount of mental effort required to process information, which can be substantial when dealing with \n",
      "ask_question\n",
      "--  [AIMessage(content='Could you share some examples or case studies where larger context windows have been successfully applied to improve retrieval relevance in real-world RAG applications?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_toke\n",
      "answer_question\n",
      "--  [AIMessage(content='While specific case studies might not be publicly detailed in published research, large context window models have shown promise in several areas relevant to RAG frameworks, notably in complex document processing tasks, such as legal document analysis and scientific literature re\n",
      "ask_question\n",
      "--  [AIMessage(content='Thank you so much for your help!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 1088, 'total_tokens': 1097, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0,\n",
      "answer_question\n",
      "--  [AIMessage(content=\"You're welcome! I'm glad I could assist you. If you have more questions or need further information, feel free to reach out.\\n\\nCitations:\\n\\n\", additional_kwargs={}, response_metadata={}, name='Subject_Matter_Expert')]\n"
     ]
    }
   ],
   "source": [
    "final_step = None\n",
    "\n",
    "initial_state = {\n",
    "    \"editor\": perspectives.editors[0],\n",
    "    \"messages\": [\n",
    "        AIMessage(\n",
    "            content=f\"So you said you were writing an article on {example_topic}?\",\n",
    "            name=\"Subject_Matter_Expert\",\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "async for step in interview_graph.astream(initial_state):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name][\"messages\"])[:300])\n",
    "final_step = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2a018373",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_state = next(iter(final_step.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c22c4bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_outline_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a Wikipedia writer. You have gathered information from experts and search engines. Now, you are refining the outline of the Wikipedia page. \\\n",
    "You need to make sure that the outline is comprehensive and specific. \\\n",
    "Topic you are writing about: {topic} \n",
    "\n",
    "Old outline:\n",
    "\n",
    "{old_outline}\"\"\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Refine the outline based on your conversations with subject-matter experts:\\n\\nConversations:\\n\\n{conversations}\\n\\nWrite the refined Wikipedia outline:\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Using turbo preview since the context can get quite long\n",
    "refine_outline_chain = refine_outline_prompt | llm.with_structured_output(\n",
    "    Outline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fb860af",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_outline = refine_outline_chain.invoke(\n",
    "    {\n",
    "        \"topic\": example_topic,\n",
    "        \"old_outline\": initial_outline.as_str,\n",
    "        \"conversations\": \"\\n\\n\".join(\n",
    "            f\"### {m.name}\\n\\n{m.content}\" for m in final_state[\"messages\"]\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04dd2cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact of Million-Plus Token Context Window Language Models on Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "## Introduction\n",
      "\n",
      "This section introduces the article's focus on the impact of million-plus token context windows in language models, defining key concepts and explaining their significance.\n",
      "\n",
      "### Overview of Language Models\n",
      "\n",
      "A discussion on the evolution of language models and their significance in natural language processing.\n",
      "\n",
      "### Understanding Context Windows\n",
      "\n",
      "An explanation of context windows within language models, emphasizing the importance of their size.\n",
      "\n",
      "### Introduction to Retrieval-Augmented Generation (RAG)\n",
      "\n",
      "A description of RAG, its role in improving language model outputs, and its applications across different fields.\n",
      "\n",
      "## Advancements in Context Window Sizes\n",
      "\n",
      "Exploration of technological and research advancements that enabled the development of language models with expansive context windows.\n",
      "\n",
      "### Technological Developments\n",
      "\n",
      "An overview of technological advancements that facilitated the increase in context window size.\n",
      "\n",
      "### Research Innovations\n",
      "\n",
      "Key research breakthroughs that have allowed for million-plus token context windows.\n",
      "\n",
      "## Impact on RAG Systems\n",
      "\n",
      "Analysis of how large context windows are reshaping the functionality and performance of RAG systems.\n",
      "\n",
      "### Enhanced Information Retrieval\n",
      "\n",
      "Discussion on how larger context windows improve the retrieval capability by processing extensive inputs.\n",
      "\n",
      "### Improved Generation Capabilities\n",
      "\n",
      "Examination of the enhancements in text generation resulting from expanded context windows.\n",
      "\n",
      "### Performance Metrics and Benchmarks\n",
      "\n",
      "A review of performance metrics comparing traditional RAG systems with those using large context windows.\n",
      "\n",
      "## Applications and Use Cases\n",
      "\n",
      "Investigation of practical applications and industries where large context window RAG models are implemented.\n",
      "\n",
      "### Industry Applications\n",
      "\n",
      "Analysis of sectors like healthcare, legal, and finance leveraging enhanced RAG models.\n",
      "\n",
      "### Academic and Research Applications\n",
      "\n",
      "Identification of uses in academia for comprehensive data analysis and synthesis.\n",
      "\n",
      "## Challenges and Limitations\n",
      "\n",
      "Consideration of the current technical and ethical challenges in implementing extensive context window models in RAG systems.\n",
      "\n",
      "### Technical Challenges\n",
      "\n",
      "Exploration of computational, data handling, and latency issues related to large context windows.\n",
      "\n",
      "### Ethical and Privacy Concerns\n",
      "\n",
      "Discussion on ethical implications, including data privacy and bias risks in managing extensive datasets.\n",
      "\n",
      "## Future Prospects\n",
      "\n",
      "Speculation on future developments and impacts of extensive context windows on RAG.\n",
      "\n",
      "### Potential Research Directions\n",
      "\n",
      "Identifies emerging research areas necessitating further exploration regarding large context windows.\n",
      "\n",
      "### Anticipated Technological Innovations\n",
      "\n",
      "Predictions on innovations that could revolutionize RAG systems by exploiting large context windows.\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "A recap of the article, summarizing the impact of large context windows on RAG and highlighting main conclusions.\n"
     ]
    }
   ],
   "source": [
    "print(refined_outline.as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ae4d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "reference_docs = [\n",
    "    Document(page_content=v, metadata={\"source\": k})\n",
    "    for k, v in final_state[\"references\"].items()\n",
    "]\n",
    "# This really doesn't need to be a vectorstore for this size of data.\n",
    "# It could just be a numpy matrix. Or you could store documents\n",
    "# across requests if you want.\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    reference_docs,\n",
    "    embedding=embeddings,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fac5c9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What's a long context LLM anyway?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7db64b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubSection(BaseModel):\n",
    "    subsection_title: str = Field(..., title=\"Title of the subsection\")\n",
    "    content: str = Field(\n",
    "        ...,\n",
    "        title=\"Full content of the subsection. Include [#] citations to the cited sources where relevant.\",\n",
    "    )\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        return f\"### {self.subsection_title}\\n\\n{self.content}\".strip()\n",
    "\n",
    "\n",
    "class WikiSection(BaseModel):\n",
    "    section_title: str = Field(..., title=\"Title of the section\")\n",
    "    content: str = Field(..., title=\"Full content of the section\")\n",
    "    subsections: Optional[List[Subsection]] = Field(\n",
    "        default=None,\n",
    "        title=\"Titles and descriptions for each subsection of the Wikipedia page.\",\n",
    "    )\n",
    "    citations: List[str] = Field(default_factory=list)\n",
    "\n",
    "    @property\n",
    "    def as_str(self) -> str:\n",
    "        subsections = \"\\n\\n\".join(\n",
    "            subsection.as_str for subsection in self.subsections or []\n",
    "        )\n",
    "        citations = \"\\n\".join([f\" [{i}] {cit}\" for i, cit in enumerate(self.citations)])\n",
    "        return (\n",
    "            f\"## {self.section_title}\\n\\n{self.content}\\n\\n{subsections}\".strip()\n",
    "            + f\"\\n\\n{citations}\".strip()\n",
    "        )\n",
    "\n",
    "\n",
    "section_writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert Wikipedia writer. Complete your assigned WikiSection from the following outline:\\n\\n\"\n",
    "            \"{outline}\\n\\nCite your sources, using the following references:\\n\\n<Documents>\\n{docs}\\n<Documents>\",\n",
    "        ),\n",
    "        (\"user\", \"Write the full WikiSection for the {section} section.\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "async def retrieve(inputs: dict):\n",
    "    docs = await retriever.ainvoke(inputs[\"topic\"] + \": \" + inputs[\"section\"])\n",
    "    formatted = \"\\n\".join(\n",
    "        [\n",
    "            f'<Document href=\"{doc.metadata[\"source\"]}\"/>\\n{doc.page_content}\\n</Document>'\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )\n",
    "    return {\"docs\": formatted, **inputs}\n",
    "\n",
    "\n",
    "section_writer = (\n",
    "    retrieve\n",
    "    | section_writer_prompt\n",
    "    | llm.with_structured_output(WikiSection)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "586e7302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Advancements in Context Window Sizes\n",
      "\n",
      "The development of language models with large context windows, such as those accommodating over a million tokens, marks a significant milestone in natural language processing. These advancements have been driven by both technological innovations and crucial research breakthroughs that together have transformed the landscape of language modeling, particularly benefiting applications like Retrieval-Augmented Generation (RAG).\n",
      "\n",
      "### Technological Developments\n",
      "\n",
      "The increase in context window sizes has been primarily fueled by advancements in computing power and storage solutions. Modern GPUs and TPUs now offer immense processing capabilities, enabling them to handle the complex computations necessary for training and operating models with extensive token capacities. Moreover, breakthroughs in distributed computing have allowed the parallel processing of immense datasets, thereby facilitating the efficient scaling of context windows. Improvements in memory management, driven by both hardware innovations and optimized algorithms, have further supported the processing and storage of larger models without compromising speed or accuracy.\n",
      "\n",
      "### Research Innovations\n",
      "\n",
      "Innovative research in model architecture and optimization has been pivotal in expanding context windows. Techniques such as sparse attention mechanisms and hierarchical modeling have allowed models to selectively focus on relevant portions of input data, effectively increasing the feasible size of context windows without a proportional increase in computational demand. Transformer-based architectures, with their self-attention capabilities, have been specifically refined to manage longer sequences of data efficiently. Additionally, research into more efficient pre-training and fine-tuning methods has contributed to the ability to incorporate and process more extensive inputs, making the use of million-plus token contexts viable and practical in real-world applications such as RAG systems.\n"
     ]
    }
   ],
   "source": [
    "section = await section_writer.ainvoke(\n",
    "    {\n",
    "        \"outline\": refined_outline.as_str,\n",
    "        \"section\": refined_outline.sections[1].section_title,\n",
    "        \"topic\": example_topic,\n",
    "    }\n",
    ")\n",
    "print(section.as_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23b9d49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "writer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert Wikipedia author. Write the complete wiki article on {topic} using the following section drafts:\\n\\n\"\n",
    "            \"{draft}\\n\\nStrictly follow Wikipedia format guidelines.\",\n",
    "        ),\n",
    "        (\n",
    "            \"user\",\n",
    "            'Write the complete Wiki article using markdown format. Organize citations using footnotes like \"[1]\",'\n",
    "            \" avoiding duplicates in the footer. Include URLs in the footer.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "writer = writer_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f38feee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Impact of Million-Plus Token Context Window Language Models on Retrieval-Augmented Generation\n",
      "\n",
      "## Advancements in Context Window Sizes\n",
      "\n",
      "The development of language models with large context windows, including those accommodating over a million tokens, marks a significant milestone in natural language processing. These advancements have been driven by both technological innovations and crucial research breakthroughs, transforming the landscape of language modeling and particularly benefiting applications like Retrieval-Augmented Generation (RAG)[1].\n",
      "\n",
      "### Technological Developments\n",
      "\n",
      "The increase in context window sizes has been primarily fueled by advancements in computing power and storage solutions. Modern GPUs and TPUs now offer immense processing capabilities, enabling them to handle the complex computations necessary for training and operating models with extensive token capacities. Additionally, breakthroughs in distributed computing have allowed parallel processing of immense datasets, facilitating efficient scaling of context windows[2]. Improvements in memory management, driven by both hardware innovations and optimized algorithms, have further supported the processing and storage of larger models without compromising speed or accuracy[3].\n",
      "\n",
      "### Research Innovations\n",
      "\n",
      "Innovative research in model architecture and optimization has been pivotal in expanding context windows. Techniques such as sparse attention mechanisms and hierarchical modeling have allowed models to selectively focus on relevant portions of input data, effectively increasing the feasible size of context windows without a proportional increase in computational demand[4]. Transformer-based architectures, with their self-attention capabilities, have been specifically refined to manage longer sequences of data efficiently. Additionally, research into more efficient pre-training and fine-tuning methods has contributed to the ability to incorporate and process more extensive inputs, making the use of million-plus token contexts viable and practical in real-world applications such as RAG systems[5].\n",
      "\n",
      "## Impacts on Retrieval-Augmented Generation\n",
      "\n",
      "The enhancements in language model capabilities brought by larger context windows have significant implications for Retrieval-Augmented Generation (RAG) systems. By using million-plus token context windows, RAG systems can integrate vastly more comprehensive pieces of information during the generation phase, leading to more accurate and contextually relevant outputs. The ability to reference larger amounts of data enhances the richness and informativeness of the generated responses, improving the overall user experience in applications such as conversational agents, information retrieval systems, and complex query answering tasks[6].\n",
      "\n",
      "## Conclusion\n",
      "\n",
      "The impact of million-plus token context windows on language models has notably advanced the capabilities of Retrieval-Augmented Generation systems. The blend of technological advancements and research innovations has created a conducive environment for sustaining larger context windows, enhancing the efficacy of language models in understanding and generating human-like text responses[7]. As these developments continue, further opportunities for expanding and refining context use in language models will likely arise, propelling future breakthroughs in natural language processing.\n",
      "\n",
      "## References\n",
      "\n",
      "[1] Developments in NLP Context Windows, Journal of Computational Linguistics. Available from: https://example.com/context-windows\n",
      "\n",
      "[2] Technical Advancements in Computing Power, Tech Insights. Available from: https://example.com/advancements-computing\n",
      "\n",
      "[3] Memory Management Optimizations in NLP, AI Research Blog. Available from: https://example.com/memory-management\n",
      "\n",
      "[4] Sparse Attention Mechanisms, Deep Learning Papers. Available from: https://example.com/sparse-attention\n",
      "\n",
      "[5] Refinements in Transformer Architectures, Machine Learning Review. Available from: https://example.com/transformer-refinements\n",
      "\n",
      "[6] Impact on RAG Systems, Natural Language Processing Systems Textbook. Available from: https://example.com/impact-rag\n",
      "\n",
      "[7] Future Implications of Large Context Models, Computational Future Journal. Available from: https://example.com/future-implications"
     ]
    }
   ],
   "source": [
    "for tok in writer.stream({\"topic\": example_topic, \"draft\": section.as_str}):\n",
    "    print(tok, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68f6329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    outline: Outline\n",
    "    editors: List[Editor]\n",
    "    interview_results: List[InterviewState]\n",
    "    # The final sections output\n",
    "    sections: List[WikiSection]\n",
    "    article: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c73f3f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "async def initialize_research(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    coros = (\n",
    "        generate_outline_direct.ainvoke({\"topic\": topic}),\n",
    "        survey_subjects.ainvoke(topic),\n",
    "    )\n",
    "    results = await asyncio.gather(*coros)\n",
    "    return {\n",
    "        **state,\n",
    "        \"outline\": results[0],\n",
    "        \"editors\": results[1].editors,\n",
    "    }\n",
    "\n",
    "\n",
    "async def conduct_interviews(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    initial_states = [\n",
    "        {\n",
    "            \"editor\": editor,\n",
    "            \"messages\": [\n",
    "                AIMessage(\n",
    "                    content=f\"So you said you were writing an article on {topic}?\",\n",
    "                    name=\"Subject_Matter_Expert\",\n",
    "                )\n",
    "            ],\n",
    "        }\n",
    "        for editor in state[\"editors\"]\n",
    "    ]\n",
    "    # We call in to the sub-graph here to parallelize the interviews\n",
    "    interview_results = await interview_graph.abatch(initial_states)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"interview_results\": interview_results,\n",
    "    }\n",
    "\n",
    "\n",
    "def format_conversation(interview_state):\n",
    "    messages = interview_state[\"messages\"]\n",
    "    convo = \"\\n\".join(f\"{m.name}: {m.content}\" for m in messages)\n",
    "    return f'Conversation with {interview_state[\"editor\"].name}\\n\\n' + convo\n",
    "\n",
    "\n",
    "async def refine_outline(state: ResearchState):\n",
    "    convos = \"\\n\\n\".join(\n",
    "        [\n",
    "            format_conversation(interview_state)\n",
    "            for interview_state in state[\"interview_results\"]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    updated_outline = await refine_outline_chain.ainvoke(\n",
    "        {\n",
    "            \"topic\": state[\"topic\"],\n",
    "            \"old_outline\": state[\"outline\"].as_str,\n",
    "            \"conversations\": convos,\n",
    "        }\n",
    "    )\n",
    "    return {**state, \"outline\": updated_outline}\n",
    "\n",
    "\n",
    "async def index_references(state: ResearchState):\n",
    "    all_docs = []\n",
    "    for interview_state in state[\"interview_results\"]:\n",
    "        reference_docs = [\n",
    "            Document(page_content=v, metadata={\"source\": k})\n",
    "            for k, v in interview_state[\"references\"].items()\n",
    "        ]\n",
    "        all_docs.extend(reference_docs)\n",
    "    await vectorstore.aadd_documents(all_docs)\n",
    "    return state\n",
    "\n",
    "\n",
    "async def write_sections(state: ResearchState):\n",
    "    outline = state[\"outline\"]\n",
    "    sections = await section_writer.abatch(\n",
    "        [\n",
    "            {\n",
    "                \"outline\": refined_outline.as_str,\n",
    "                \"section\": section.section_title,\n",
    "                \"topic\": state[\"topic\"],\n",
    "            }\n",
    "            for section in outline.sections\n",
    "        ]\n",
    "    )\n",
    "    return {\n",
    "        **state,\n",
    "        \"sections\": sections,\n",
    "    }\n",
    "\n",
    "\n",
    "async def write_article(state: ResearchState):\n",
    "    topic = state[\"topic\"]\n",
    "    sections = state[\"sections\"]\n",
    "    draft = \"\\n\\n\".join([section.as_str for section in sections])\n",
    "    article = await writer.ainvoke({\"topic\": topic, \"draft\": draft})\n",
    "    return {\n",
    "        **state,\n",
    "        \"article\": article,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7441fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "builder_of_storm = StateGraph(ResearchState)\n",
    "\n",
    "nodes = [\n",
    "    (\"init_research\", initialize_research),\n",
    "    (\"conduct_interviews\", conduct_interviews),\n",
    "    (\"refine_outline\", refine_outline),\n",
    "    (\"index_references\", index_references),\n",
    "    (\"write_sections\", write_sections),\n",
    "    (\"write_article\", write_article),\n",
    "]\n",
    "for i in range(len(nodes)):\n",
    "    name, node = nodes[i]\n",
    "    builder_of_storm.add_node(name, node, retry=RetryPolicy(max_attempts=3))\n",
    "    if i > 0:\n",
    "        builder_of_storm.add_edge(nodes[i - 1][0], name)\n",
    "\n",
    "builder_of_storm.add_edge(START, nodes[0][0])\n",
    "builder_of_storm.add_edge(nodes[-1][0], END)\n",
    "storm = builder_of_storm.compile(checkpointer=MemorySaver())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37eca39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(storm.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8119385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniforge3/envs/langgraph/lib/python3.11/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /home/ubuntu/miniforge3/envs/langgraph/lib/python3.11/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_research\n",
      "--  {'topic': 'Groq, NVIDIA, Llamma.cpp and the future of LLM Inference', 'outline': Outline(page_title='Groq, NVIDIA, Llamma.cpp, and the Future of LLM Inference', sections=[Section(section_title='Introduction', description='An overview of the key players in the large language model (LLM) inference spa\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"my-thread\"}}\n",
    "async for step in storm.astream(\n",
    "    {\n",
    "        \"topic\": \"Groq, NVIDIA, Llamma.cpp and the future of LLM Inference\",\n",
    "    },\n",
    "    config,\n",
    "):\n",
    "    name = next(iter(step))\n",
    "    print(name)\n",
    "    print(\"-- \", str(step[name])[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560d24a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
